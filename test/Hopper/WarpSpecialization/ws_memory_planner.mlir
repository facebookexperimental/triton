// RUN: not triton-opt %s -split-input-file --nvgpu-test-ws-memory-planner=num-buffers=3 2>&1 | FileCheck %s

// Test case: Attention backward pass with TMEM allocations and tc_gen5_mma operations.
// This IR has already been processed by the memory planner (after doBufferAllocation).
// Running the memory planner again should fail because TMEM space cannot be allocated
// for the already-allocated buffers.
//
// The test verifies that the pass correctly reports the out-of-memory condition
// when trying to re-allocate TMEM space.

// CHECK: error: can't find tmem space
module attributes {"ttg.cluster-dim-x" = 1 : i32, "ttg.cluster-dim-y" = 1 : i32, "ttg.cluster-dim-z" = 1 : i32, ttg.max_reg_auto_ws = 152 : i32, ttg.min_reg_auto_ws = 24 : i32, "ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 4 : i32, ttg.target = "cuda:100", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @_attn_bwd(%arg0: !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, %arg1: i32, %arg2: i32, %arg3: i64, %arg4: i64, %arg5: !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, %arg6: i32, %arg7: i32, %arg8: i64, %arg9: i64, %arg10: !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, %arg11: i32, %arg12: i32, %arg13: i64, %arg14: i64, %arg15: f32, %arg16: !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, %arg17: i32, %arg18: i32, %arg19: i64, %arg20: i64, %arg21: !tt.tensordesc<tensor<128x128xf32, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 32}>>>, %arg22: i32, %arg23: i32, %arg24: i64, %arg25: i64, %arg26: !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, %arg27: i32, %arg28: i32, %arg29: i64, %arg30: i64, %arg31: !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, %arg32: i32, %arg33: i32, %arg34: i64, %arg35: i64, %arg36: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg37: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg38: i32 {tt.divisibility = 16 : i32}, %arg39: i32 {tt.divisibility = 16 : i32}, %arg40: i32 {tt.divisibility = 16 : i32}, %arg41: i32 {tt.divisibility = 16 : i32}, %arg42: i32 {tt.divisibility = 16 : i32}) attributes {noinline = false} {
    %0 = ttg.local_alloc : () -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
    %result = ttng.tmem_alloc : () -> !ttg.memdesc<128x128xbf16, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = false>, #ttng.tensor_memory, mutable>
    %result_0 = ttng.tmem_alloc : () -> !ttg.memdesc<128x128xbf16, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = false>, #ttng.tensor_memory, mutable>
    %1 = ttg.local_alloc : () -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
    %2 = ttg.local_alloc {async_task_id = array<i32: 5>} : () -> !ttg.memdesc<128x128xf32, #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [0, 1]}>, #ttg.shared_memory, mutable>
    %3 = ttg.local_alloc : () -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
    %false = arith.constant {async_task_id = array<i32: 0>} false
    %true = arith.constant {async_task_id = array<i32: 0, 5>} true
    %c128_i32 = arith.constant {async_task_id = array<i32: 0, 1, 3, 4, 5>} 128 : i32
    %c0_i32 = arith.constant {async_task_id = array<i32: 0, 1, 3, 4, 5>} 0 : i32
    %c1_i32 = arith.constant {async_task_id = array<i32: 0, 1, 3, 4, 5>} 1 : i32
    %cst = arith.constant {async_task_id = array<i32: 3>} dense<0.693147182> : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %cst_1 = arith.constant {async_task_id = array<i32: 0, 5>} dense<0.000000e+00> : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %4 = tt.get_program_id z {async_task_id = array<i32: 0, 1, 3, 4, 5>} : i32
    %5 = arith.muli %4, %arg42 {async_task_id = array<i32: 4, 5>} : i32
    %6 = arith.extsi %5 {async_task_id = array<i32: 4, 5>} : i32 to i64
    %7 = arith.remsi %4, %arg41 {async_task_id = array<i32: 0, 1, 3, 5>} : i32
    %8 = arith.muli %arg39, %7 {async_task_id = array<i32: 0, 1, 3, 5>} : i32
    %9 = arith.divsi %4, %arg41 {async_task_id = array<i32: 0, 1, 3, 5>} : i32
    %10 = arith.muli %arg38, %9 {async_task_id = array<i32: 0, 1, 3, 5>} : i32
    %11 = arith.addi %8, %10 {async_task_id = array<i32: 0, 1, 3, 5>} : i32
    %12 = arith.extsi %11 {async_task_id = array<i32: 0, 1, 3, 5>} : i32 to i64
    %13 = arith.extsi %arg40 {async_task_id = array<i32: 0, 1, 3, 5>} : i32 to i64
    %14 = arith.divsi %12, %13 {async_task_id = array<i32: 0, 1, 3, 5>} : i64
    %15 = tt.get_program_id x {async_task_id = array<i32: 0, 5>} : i32
    %16 = tt.addptr %arg36, %6 {async_task_id = array<i32: 5>} : !tt.ptr<f32>, i64
    %17 = tt.addptr %arg37, %6 {async_task_id = array<i32: 4>} : !tt.ptr<f32>, i64
    %18 = arith.muli %15, %c128_i32 {async_task_id = array<i32: 0, 5>} : i32
    %19 = arith.extsi %18 {async_task_id = array<i32: 0, 5>} : i32 to i64
    %20 = arith.addi %14, %19 {async_task_id = array<i32: 0, 5>} : i64
    %21 = arith.trunci %20 {async_task_id = array<i32: 0, 5>} : i64 to i32
    %22 = tt.descriptor_load %arg5[%21, %c0_i32] {async_task_id = array<i32: 0>} : !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>> -> tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
    %23 = ttg.local_alloc %22 {async_task_id = array<i32: 0>} : (tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>) -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory>
    %24 = tt.descriptor_load %arg10[%21, %c0_i32] {async_task_id = array<i32: 0>} : !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>> -> tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
    %25 = ttg.local_alloc %24 {async_task_id = array<i32: 0>} : (tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>) -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory>
    %26 = arith.divsi %arg42, %c128_i32 {async_task_id = array<i32: 0, 1, 3, 4, 5>} : i32
    %27 = tt.make_range {async_task_id = array<i32: 4, 5>, end = 128 : i32, start = 0 : i32} : tensor<128xi32, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
    %28 = tt.splat %16 {async_task_id = array<i32: 5>} : !tt.ptr<f32> -> tensor<128x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
    %29 = tt.splat %17 {async_task_id = array<i32: 4>} : !tt.ptr<f32> -> tensor<128x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
    %result_2, %token = ttng.tmem_alloc {async_task_id = array<i32: 0, 5>} : () -> (!ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>, !ttg.async.token)
    %result_3, %token_4 = ttng.tmem_alloc {async_task_id = array<i32: 0, 5>} : () -> (!ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>, !ttg.async.token)
    %result_5, %token_6 = ttng.tmem_alloc {async_task_id = array<i32: 0, 4>} : () -> (!ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>, !ttg.async.token)
    %result_7, %token_8 = ttng.tmem_alloc {async_task_id = array<i32: 0, 5>} : () -> (!ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>, !ttg.async.token)
    %result_9, %token_10 = ttng.tmem_alloc {async_task_id = array<i32: 0, 3>} : () -> (!ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>, !ttg.async.token)
    %30 = ttng.tmem_store %cst_1, %result_7[%token_8], %true {async_task_id = array<i32: 0, 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>
    %31 = ttng.tmem_store %cst_1, %result_3[%token_4], %true {async_task_id = array<i32: 0, 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>
    %32:7 = scf.for %arg43 = %c0_i32 to %26 step %c1_i32 iter_args(%arg44 = %c0_i32, %arg45 = %false, %arg46 = %token, %arg47 = %31, %arg48 = %token_6, %arg49 = %30, %arg50 = %token_10) -> (i32, i1, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token)  : i32 {
      %39 = arith.extsi %arg44 {async_task_id = array<i32: 1, 3>} : i32 to i64
      %40 = arith.addi %14, %39 {async_task_id = array<i32: 1, 3>} : i64
      %41 = arith.trunci %40 {async_task_id = array<i32: 1, 3>} : i64 to i32
      %42 = tt.descriptor_load %arg0[%41, %c0_i32] {async_task_id = array<i32: 1>} : !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>> -> tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
      ttg.local_store %42, %3 {async_task_id = array<i32: 1>} : tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>> -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
      %43 = ttg.memdesc_trans %3 {async_task_id = array<i32: 0>, order = array<i32: 1, 0>} : !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
      %44 = tt.splat %arg44 {async_task_id = array<i32: 4, 5>} : i32 -> tensor<128xi32, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
      %45 = arith.addi %44, %27 {async_task_id = array<i32: 4, 5>} : tensor<128xi32, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
      %46 = tt.addptr %28, %45 {async_task_id = array<i32: 5>} : tensor<128x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<128xi32, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
      %47 = tt.load %46 {async_task_id = array<i32: 5>} : tensor<128x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
      %48 = ttng.tc_gen5_mma %23, %43, %result_2[%arg46], %false, %true {async_task_id = array<i32: 0>} : !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory>, !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>, #ttg.shared_memory, mutable>, !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>
      %49 = ttg.convert_layout %47 {async_task_id = array<i32: 5>} : tensor<128xf32, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<128xf32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
      %50 = tt.expand_dims %49 {async_task_id = array<i32: 5>, axis = 0 : i32} : tensor<128xf32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<1x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %51 = tt.broadcast %50 {async_task_id = array<i32: 5>} : tensor<1x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %result_15, %token_16 = ttng.tmem_load %result_2[%48] {async_task_id = array<i32: 5>} : !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %52 = arith.subf %result_15, %51 {async_task_id = array<i32: 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %53 = math.exp2 %52 {async_task_id = array<i32: 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      ttg.local_store %53, %2 {async_task_id = array<i32: 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> !ttg.memdesc<128x128xf32, #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [0, 1]}>, #ttg.shared_memory, mutable>
      %54 = tt.descriptor_load %arg16[%41, %c0_i32] {async_task_id = array<i32: 1>} : !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>> -> tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
      ttg.local_store %54, %1 {async_task_id = array<i32: 1>} : tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>> -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
      %55 = arith.truncf %53 {async_task_id = array<i32: 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %true_17 = arith.constant {async_task_id = array<i32: 5>} true
      ttng.tmem_store %55, %result_0, %true_17 {async_task_id = array<i32: 5>} : tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> !ttg.memdesc<128x128xbf16, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = false>, #ttng.tensor_memory, mutable>
      %56 = ttng.tc_gen5_mma %result_0, %1, %result_3[%arg47], %arg45, %true {async_task_id = array<i32: 0>} : !ttg.memdesc<128x128xbf16, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = false>, #ttng.tensor_memory, mutable>, !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>, !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>
      %57 = tt.addptr %29, %45 {async_task_id = array<i32: 4>} : tensor<128x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>, tensor<128xi32, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
      %58 = tt.load %57 {async_task_id = array<i32: 4>} : tensor<128x!tt.ptr<f32>, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>>
      %59 = ttg.memdesc_trans %1 {async_task_id = array<i32: 0>, order = array<i32: 1, 0>} : !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
      %60 = ttng.tc_gen5_mma %25, %59, %result_5[%arg48], %false, %true {async_task_id = array<i32: 0>} : !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory>, !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>, #ttg.shared_memory, mutable>, !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>
      %61 = ttg.convert_layout %58 {async_task_id = array<i32: 4>} : tensor<128xf32, #ttg.blocked<{sizePerThread = [1], threadsPerWarp = [32], warpsPerCTA = [4], order = [0]}>> -> tensor<128xf32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>>
      %62 = tt.expand_dims %61 {async_task_id = array<i32: 4>, axis = 0 : i32} : tensor<128xf32, #ttg.slice<{dim = 0, parent = #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>}>> -> tensor<1x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %63 = tt.broadcast %62 {async_task_id = array<i32: 4>} : tensor<1x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %result_18, %token_19 = ttng.tmem_load %result_5[%60] {async_task_id = array<i32: 4>} : !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %64 = arith.subf %result_18, %63 {async_task_id = array<i32: 4>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %65 = ttg.local_load %2 {async_task_id = array<i32: 4>} : !ttg.memdesc<128x128xf32, #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [0, 1]}>, #ttg.shared_memory, mutable> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %66 = arith.mulf %65, %64 {async_task_id = array<i32: 4>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %67 = arith.truncf %66 {async_task_id = array<i32: 4>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %true_20 = arith.constant {async_task_id = array<i32: 4>} true
      ttng.tmem_store %67, %result, %true_20 {async_task_id = array<i32: 4>} : tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> !ttg.memdesc<128x128xbf16, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = false>, #ttng.tensor_memory, mutable>
      %68 = ttng.tc_gen5_mma %result, %3, %result_7[%arg49], %arg45, %true {async_task_id = array<i32: 0>} : !ttg.memdesc<128x128xbf16, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = false>, #ttng.tensor_memory, mutable>, !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>, !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>
      ttg.local_store %67, %0 {async_task_id = array<i32: 4>} : tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
      %69 = ttg.memdesc_trans %0 {async_task_id = array<i32: 0>, order = array<i32: 1, 0>} : !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>, #ttg.shared_memory, mutable> -> !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>
      %70 = ttng.tc_gen5_mma %69, %23, %result_9[%arg50], %false, %true {async_task_id = array<i32: 0>} : !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory, mutable>, !ttg.memdesc<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>, #ttg.shared_memory>, !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable>
      %result_21, %token_22 = ttng.tmem_load %result_9[%70] {async_task_id = array<i32: 3>} : !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %71 = arith.mulf %result_21, %cst {async_task_id = array<i32: 3>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
      %72 = ttg.convert_layout %71 {async_task_id = array<i32: 3>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
      tt.descriptor_reduce add, %arg21[%41, %c0_i32], %72 {async_task_id = array<i32: 3>} : !tt.tensordesc<tensor<128x128xf32, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 32}>>>, tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
      %73 = arith.addi %arg44, %c128_i32 {async_task_id = array<i32: 1, 3, 4, 5>} : i32
      scf.yield {async_task_id = array<i32: 0, 1, 3, 4, 5>} %73, %true, %token_16, %56, %token_19, %68, %token_22 : i32, i1, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token, !ttg.async.token
    } {async_task_id = array<i32: 0, 1, 3, 4, 5>, tt.warp_specialize, ttg.partition.stages = [0 : i32, 1 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32, 0 : i32], ttg.warp_specialize.tag = 0 : i32}
    %result_11, %token_12 = ttng.tmem_load %result_3[%32#3] {async_task_id = array<i32: 5>} : !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %33 = arith.truncf %result_11 {async_task_id = array<i32: 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %result_13, %token_14 = ttng.tmem_load %result_7[%32#5] {async_task_id = array<i32: 5>} : !ttg.memdesc<128x128xf32, #ttng.tensor_memory_encoding<blockM = 128, blockN = 128, unpacked = true>, #ttng.tensor_memory, mutable> -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %34 = ttg.convert_layout %33 {async_task_id = array<i32: 5>} : tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
    tt.descriptor_store %arg31[%21, %c0_i32], %34 {async_task_id = array<i32: 5>} : !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
    %35 = tt.splat %arg15 {async_task_id = array<i32: 5>} : f32 -> tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %36 = arith.mulf %result_13, %35 {async_task_id = array<i32: 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %37 = arith.truncf %36 {async_task_id = array<i32: 5>} : tensor<128x128xf32, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> to tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>>
    %38 = ttg.convert_layout %37 {async_task_id = array<i32: 5>} : tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 128], threadsPerWarp = [32, 1], warpsPerCTA = [4, 1], order = [0, 1]}>> -> tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
    tt.descriptor_store %arg26[%21, %c0_i32], %38 {async_task_id = array<i32: 5>} : !tt.tensordesc<tensor<128x128xbf16, #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>>>, tensor<128x128xbf16, #ttg.blocked<{sizePerThread = [1, 1], threadsPerWarp = [1, 32], warpsPerCTA = [1, 4], order = [1, 0]}>>
    tt.return
  }
}
